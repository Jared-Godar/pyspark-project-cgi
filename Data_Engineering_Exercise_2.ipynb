{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "73b64066",
      "metadata": {
        "id": "73b64066"
      },
      "source": [
        "#### Data Engineering Exercise 2: Pyspark / SQL \n",
        "The Parking Citation Dataset is a puplic dataset collecting millions of records information about parking tickets for a county in California. We only selected a million of this data for us to work with in this assignment. You can see the whole dataset here: https://data.lacity.org/Transportation/Parking-Citations/wjz9-h9np/data\n",
        "\n",
        "In this asssignment we want you to Extract data, Clean data, Create a report, and then the report as a new file. Steps are:\n",
        "\n",
        "    1.  Read the parquet file written in First Assignemtn as a \"Pyspark\" DataFrame.\n",
        "    2. Count number distinct values for each column\n",
        "    3.  Count nulls in every column\n",
        "    4.  Write a function to drop columns with more than 1% missing values\n",
        "    5.  Impute missing values for \"Fine_amount\" column with \"median\" using \"Imputer\" package from Pyspark\n",
        "    6.  Drop rows with at least two null values \n",
        "    7.  Extract values of a string column and create new columns based on thoes values \n",
        "    8. Create a broadcast variable stores the full names of states. Show a dataframe output showing the states full names. \n",
        "\n",
        "    Read the questions carefully and Export three reports based on them:\n",
        "        9.  Create First report, then Export it as \"Report_Make_State_Fine\" \n",
        "        10.  Create Second Report, then Export it as \"Report_HOND_2016\"\n",
        "        11. Create Third Report, then Export it as \"Report_Parking_Fines_2016\"\n",
        "\n",
        "  \n",
        "Here are some resources that you may need: \n",
        "\n",
        "    Pyspark =  https://sparkbyexamples.com/\n",
        "   \n",
        "Good luck!  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bf4077",
      "metadata": {
        "id": "a4bf4077"
      },
      "source": [
        "##### IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e6a1af",
      "metadata": {
        "id": "b7e6a1af"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "926a666a",
      "metadata": {
        "id": "926a666a"
      },
      "source": [
        "##### 1. Read the Parquet file written in First Assignment as a \"Pyspark\" DataFrame. Print the size of columns and rows of it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2efe79a6",
      "metadata": {
        "id": "2efe79a6"
      },
      "outputs": [],
      "source": [
        "# read the parquet file from previous step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc98c3c3",
      "metadata": {
        "id": "bc98c3c3"
      },
      "outputs": [],
      "source": [
        "# print size of the dataframe \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91175a5",
      "metadata": {
        "id": "e91175a5"
      },
      "source": [
        "##### 2. Count number distinct values for each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6100843a",
      "metadata": {
        "id": "6100843a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "142e8242",
      "metadata": {
        "id": "142e8242"
      },
      "source": [
        "##### 3. Count number of null in every column. Feel free to change the data types if needed. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dae9c37",
      "metadata": {
        "id": "3dae9c37"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b3545d",
      "metadata": {
        "id": "25b3545d"
      },
      "source": [
        "##### 4. Write a function to drop columns with more than 1% missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6c72c2",
      "metadata": {
        "id": "6e6c72c2"
      },
      "outputs": [],
      "source": [
        "percent = 0.01\n",
        "def drop_null_columns(df, percent):\n",
        "    \n",
        "    *** WRITE YOUR CODE TO complete the function ***\n",
        "    \n",
        "    return df, to_drop\n",
        "\n",
        "df_spark, dropped_columns = drop_null_columns(df_spark, percent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deef02fc",
      "metadata": {
        "id": "deef02fc"
      },
      "source": [
        "##### 5. Impute missing values for \"Fine_amount\" column with \"median\" using \"Imputer\" package from Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b2362bc",
      "metadata": {
        "id": "7b2362bc"
      },
      "outputs": [],
      "source": [
        "# check the Fine_amount column datatype. You may need to change it to DoubleType()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe983bf2",
      "metadata": {
        "id": "fe983bf2"
      },
      "outputs": [],
      "source": [
        "# use imputer package with Median \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85cad595",
      "metadata": {
        "id": "85cad595"
      },
      "source": [
        "##### 6.  Drop \"rows\" with at least two null values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1863aa",
      "metadata": {
        "id": "ad1863aa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d181a2d",
      "metadata": {
        "id": "1d181a2d"
      },
      "source": [
        "##### 7. Extract day and month from Issue_Date column and then drop the \"Issue_Date\", and \"__index_level_0__\" column (if exist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a8f100",
      "metadata": {
        "id": "09a8f100"
      },
      "outputs": [],
      "source": [
        "# extract day and month from Issue_Date column \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b0dbce",
      "metadata": {
        "id": "35b0dbce"
      },
      "outputs": [],
      "source": [
        "# Then drop the Issue_Date column, and \"index_level_0\" column (if exist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####8. Create a broadcast variable stores the full names of states. Show a dataframe output showing the states full names. \n",
        "\n"
      ],
      "metadata": {
        "id": "KJb5u7X9Fo-7"
      },
      "id": "KJb5u7X9Fo-7"
    },
    {
      "cell_type": "code",
      "source": [
        "##Dictionary of States\n",
        "states = {\n",
        "        'AK': 'Alaska', 'AL': 'Alabama','AR': 'Arkansas','AS': 'American Samoa','AZ': 'Arizona', 'CA': 'California',\n",
        "'CO': 'Colorado','CT': 'Connecticut','DC': 'District of Columbia','DE': 'Delaware','FL': 'Florida','GA': 'Georgia','GU': 'Guam','HI': 'Hawaii','IA': 'Iowa','ID': 'Idaho','IL': 'Illinois','IN': 'Indiana',\n",
        "'KS': 'Kansas','KY': 'Kentucky','LA': 'Louisiana','MA': 'Massachusetts','MD': 'Maryland',\n",
        "'ME': 'Maine','MI': 'Michigan','MN': 'Minnesota','MO': 'Missouri','MP': 'Northern Mariana Islands','MS': 'Mississippi','MT': 'Montana','NA': 'National','NC': 'North Carolina','ND': 'North Dakota','NE': 'Nebraska',\n",
        "'NH': 'New Hampshire','NJ': 'New Jersey','NM': 'New Mexico','NV': 'Nevada','NY': 'New York','OH': 'Ohio','OK': 'Oklahoma','OR': 'Oregon','PA': 'Pennsylvania','PR': 'Puerto Rico',\n",
        "'RI': 'Rhode Island','SC': 'South Carolina','SD': 'South Dakota','TN': 'Tennessee','TX': 'Texas','UT': 'Utah','VA': 'Virginia','VI': 'Virgin Islands','VT': 'Vermont','WA': 'Washington','WI':'Wisconsin','WV': 'West Virginia','WY': 'Wyoming'\n",
        "}\n",
        "\n",
        "###create broadcast variable\n",
        "\n",
        "\n",
        "###Display output of column with states full names. \n"
      ],
      "metadata": {
        "id": "JatbNqeiGGES"
      },
      "id": "JatbNqeiGGES",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "000141e9",
      "metadata": {
        "id": "000141e9"
      },
      "source": [
        "### Read the questions below and Export three reports based on them:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d6d15f",
      "metadata": {
        "id": "37d6d15f"
      },
      "source": [
        "##### 9. First Report:\n",
        "Create a report table to get the Sum of \"Fine_Amouns\" for each State Plates (\"RP_State_Plate\" column) for each selected vehicle make company (\"Make\" column). \n",
        "The selected brands are: \n",
        "\n",
        "Make_Cars = [\"ACUR\", \"AUDI\", \"DODG\", \"BMW\", \"BUIC\", \"CHEV\", \"CHRY\", \"NISS\"\n",
        "             ,\"FIAT\", \"FORD\", \"GMC\", \"JEEP\", \"KIA\", \"VOLV\", \"TOYT\", \"SUBA\", \"MAZD\"]\n",
        "\n",
        "The final report should look like below:\n",
        "\n",
        "![report_table.PNG](attachment:report_table.PNG)            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad5e1db",
      "metadata": {
        "id": "6ad5e1db"
      },
      "outputs": [],
      "source": [
        "Make_Cars = [\"ACUR\", \"AUDI\", \"DODG\", \"BMW\", \"BUIC\", \"CHEV\", \"CHRY\", \"NISS\"\n",
        "             ,\"FIAT\", \"FORD\", \"GMC\", \"JEEP\", \"KIA\", \"VOLV\", \"TOYT\", \"SUBA\", \"MAZD\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6078be",
      "metadata": {
        "id": "5f6078be"
      },
      "outputs": [],
      "source": [
        "# create the repoort \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "960cbd59",
      "metadata": {
        "id": "960cbd59"
      },
      "outputs": [],
      "source": [
        "# export the report a CSV with header and \"|\" deliminer. Name it as Report_Make_State_Fine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b80c5e88",
      "metadata": {
        "id": "b80c5e88"
      },
      "source": [
        "##### 10. Second Report:\n",
        "Filter the dataframe where Make = HOND and get a count of total violation descriptions per category in 2016 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f54758e",
      "metadata": {
        "id": "7f54758e"
      },
      "outputs": [],
      "source": [
        "# create the report \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d9d8bb3",
      "metadata": {
        "id": "6d9d8bb3"
      },
      "outputs": [],
      "source": [
        "# export the report as a CSV with header and \",\" deliminer. Name it as Report_HOND_2016.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a295a346",
      "metadata": {
        "id": "a295a346"
      },
      "source": [
        "##### 11. Third Report:\n",
        "Create a new dataframe from the original dataset, drop everything before 2016 date, and only use the below columns:\n",
        "keep_columns=['Ticket_number', 'RP_State_Plate', 'Make', 'Body_Style', 'Fine_amount']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b7b990",
      "metadata": {
        "id": "c9b7b990"
      },
      "outputs": [],
      "source": [
        "keep_columns=['Ticket_number', 'RP_State_Plate', 'Make', 'Body_Style', 'Fine_amount']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193b4a00",
      "metadata": {
        "id": "193b4a00"
      },
      "outputs": [],
      "source": [
        "# create the repoort \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e56e4e",
      "metadata": {
        "id": "e7e56e4e"
      },
      "outputs": [],
      "source": [
        "# export the report as a CSV with header and \",\" deliminer. Name it as Report_Parking_Fines_2016.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Data_Engineering_Exercise_2 (1).ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}